{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956f5476-d65b-4a4e-aa0b-7057f62cb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os \n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320121cd-9efb-4169-b770-779205a695ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ByteEmbedding(nn.Module):\n",
    "    def __init__(self,d_model,hash_size):\n",
    "        super().__init__()\n",
    "        self.byte_embed = nn.Embedding(256,d_model)\n",
    "        self.hash_embed = nn.Embedding(hash_size,d_model)\n",
    "\n",
    "    def forward(self,byte_seq,hash_seq):\n",
    "        byte_embedding = self.byte_embed(byte_seq)\n",
    "        hash_embedding = self.hash_embed(hash_seq)\n",
    "        return byte_embedding + hash_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c063cd79-e47b-4de4-8331-f164e923dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self,d_model,ff_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(d_model,ff_dim)\n",
    "        self.layer2 = nn.Linear(ff_dim,d_model)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layer2(self.dropout(self.gelu(self.layer1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de23bb2-82ab-4053-be6e-121790453b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,ff_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(d_model,n_heads,dropout=dropout)\n",
    "        self.ff = FeedForwardLayer(d_model,ff_dim,dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x,attn_mask = None):\n",
    "        attn_out,_ = self.attention(x,x,x,attn_mask=attn_mask) \n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        ff_out = self.ff(x)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        return self.norm2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1aa5212-06da-4d27-9ca1-1ddedbfd8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self,query_dim,key_dim,n_heads,ff_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(query_dim,n_heads,dropout=dropout)\n",
    "        self.norm = nn.LayerNorm(query_dim)\n",
    "        self.ff = FeedForwardLayer(query_dim,ff_dim,dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.query_proj = nn.Linear(query_dim,query_dim)\n",
    "        self.key_proj = nn.Linear(key_dim,query_dim)\n",
    "        self.value_proj = nn.Linear(key_dim,query_dim)\n",
    "\n",
    "    def forward(self,query,key,value):\n",
    "        query = self.query_proj(query).permute(1,0,2)\n",
    "        key = self.key_proj(key).permute(1,0,2)\n",
    "        value = self.value_proj(value).permute(1,0,2)\n",
    "\n",
    "        attn_out , _ = self.attention(query,key,value)\n",
    "        attn_out = attn_out.permute(1,0,2)\n",
    "        query = query.permute(1,0,2)\n",
    "        query = query + self.dropout(attn_out)\n",
    "        query = self.norm(query)\n",
    "        ff_out = self.ff(query)\n",
    "        return query + self.dropout(ff_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e3d083-0f43-4283-ae5c-cb2d18f1ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEncoder(nn.Module):\n",
    "    def __init__(self,byte_dim,n_heads,ff_dim,n_layers,dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([TransformerBlock(byte_dim,n_heads,ff_dim,dropout) for _ in range(n_layers)])\n",
    "        self.cross_attn = CrossAttentionBlock(query_dim=byte_dim,key_dim=byte_dim,n_heads=n_heads,ff_dim=ff_dim,dropout=dropout)\n",
    "\n",
    "    def forward(self,byte_embeddings,patch_embeddings):\n",
    "        for layer in self.layers:\n",
    "            byte_embeddings = layer(byte_embeddings)\n",
    "        patch_embedding = self.cross_attn(patch_embeddings,byte_embeddings,byte_embeddings)\n",
    "        return patch_embedding\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a27d8fe-bc54-4aa7-ad7f-304cbbc94477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentGlobalTransformer(nn.Module):\n",
    "    def __init__(self,patch_dim,n_heads,ff_dim,n_layers,dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([TransformerBlock(patch_dim,n_heads,ff_dim,dropout) for _ in range(n_layers)])\n",
    "    def forward(self,patches,attn_mask=None):\n",
    "        for layer in self.layers:\n",
    "            patches = layer(patches,attn_mask=attn_mask)\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d507b0f2-81b2-4280-bf8e-31c0800b6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalDecoder(nn.Module):\n",
    "    def __init__(self,patch_dim,byte_dim,n_heads,ff_dim,n_layers,dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([TransformerBlock(byte_dim,n_heads,ff_dim,dropout) for _ in range(n_layers)])\n",
    "        self.cross_attn = CrossAttentionBlock(query_dim=byte_dim,key_dim=patch_dim,n_heads=n_heads,ff_dim=ff_dim,dropout=dropout)\n",
    "        self.output_proj = nn.Linear(byte_dim,256)\n",
    "\n",
    "    def forward(self,patch_embedding,byte_embedding):\n",
    "        byte_embedding = self.cross_attn(byte_embedding,patch_embedding,patch_embedding)\n",
    "        for layer in self.layers:\n",
    "            byte_embedding = layer(byte_embedding)\n",
    "        return self.output_proj(byte_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18ad604-3ab6-4cca-8954-40a2c3152de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ByteLatentTransformer(nn.Module):\n",
    "    def __init__(self,byte_dim,patch_dim,vocab_size,n_heads,ff_dim,n_encoder,n_decoder,n_global,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.byte_embed = ByteEmbedding(byte_dim,vocab_size)\n",
    "        self.local_encoder = LocalEncoder(byte_dim,n_heads,ff_dim,n_layers=n_encoder,dropout=dropout)\n",
    "        self.global_transformer = LatentGlobalTransformer(patch_dim,n_heads,ff_dim,n_layers=n_global,dropout=dropout)\n",
    "        self.local_decoder = LocalDecoder(patch_dim,byte_dim,n_heads,ff_dim,n_decoder,dropout=dropout) \n",
    "        self.projection = nn.Linear(byte_dim,patch_dim)\n",
    "\n",
    "    def forward(self,byte_seq,hash_seq,patch_seq):\n",
    "        byte_embeddings = self.byte_embed(byte_seq,hash_seq)\n",
    "        if patch_seq is None:\n",
    "            patch_embeddings = torch.mean(byte_embeddings,dim=1,keepdim=True)\n",
    "            patch_embeddings = self.local_encoder(byte_embeddings,patch_embeddings)\n",
    "            patch_embeddings = self.projection(patch_embeddings)\n",
    "        else:\n",
    "            patch_embeddings = patch_seq\n",
    "        patch_embeddings = self.global_transformer(patch_embeddings)\n",
    "        byte_output = self.local_decoder(patch_embeddings,byte_embeddings)\n",
    "        return byte_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ac7e4d-2941-459b-baa3-4ac3fa4f2183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa8f1d-e486-4747-b9c0-2cad4ca819c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6481/1815865120.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filepath, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from epoch 40!\n",
      "Epoch [41/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<31:45,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -9.6875, std: 6.9922, min: -25.2188, max: 13.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:53<00:00, 29.35it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Train Loss: 2.2772, Validation Loss: 2.2742\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 41!\n",
      "Sample Generated Text:\n",
      "The Chiffomum mm the the hanlitt To Tued . .. s . . Intanson d wodowat we . tort oo alllentititititrilices womenthe t ata aieaional \n",
      "Epoch [42/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:20,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -8.1016, std: 5.8359, min: -23.7656, max: 12.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:51<00:00, 29.46it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Train Loss: 2.2548, Validation Loss: 2.2623\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 42!\n",
      "Sample Generated Text:\n",
      "The The Thererrerarererererelll rirrerr . . . . w . . . . . aryaravercon intons sh hivivaravian ona ooooos ass , , , , , , , , s , ,\n",
      "Epoch [43/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<29:54,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -8.9766, std: 6.5781, min: -26.0938, max: 12.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:50<00:00, 29.52it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Train Loss: 2.2441, Validation Loss: 2.2546\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 43!\n",
      "Sample Generated Text:\n",
      "The â f S n hind inirincer ar llllilalie ithecall il . a . . . g . .. . .. . . . . .. .. . .. .. . . ilalllilll S offiffaimiaserer\n",
      "Epoch [44/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:04,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -9.5156, std: 7.0742, min: -27.8281, max: 13.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:50<00:00, 29.51it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Train Loss: 2.2363, Validation Loss: 2.2488\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 44!\n",
      "Sample Generated Text:\n",
      "The Th arprlartiorourk w .. ... \" \" ' \" um ..... .. ... V. . ... d . hith akeatty . ranerankand an atyanten t . ai alil . ne , rr 2 \n",
      "Epoch [45/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:28,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -9.6094, std: 7.1680, min: -27.5469, max: 13.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:56<00:00, 29.22it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Train Loss: 2.2301, Validation Loss: 2.2441\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 45!\n",
      "Sample Generated Text:\n",
      "The Thel e is his his hos s he A A As intitit @ o a a I arear IIrrer r rorid is liler Fro , , , , , , Hie . . oo rr . ne ito rolonan\n",
      "Epoch [46/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<29:51,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -10.0156, std: 7.4414, min: -28.6094, max: 13.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [13:58<00:00, 20.79it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 90.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Train Loss: 2.2250, Validation Loss: 2.2409\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 46!\n",
      "Sample Generated Text:\n",
      "The ve D Dy Dy Dy Dat Damemmommm a is was wepphend an an anntrnorro Ar Arerr rrrerarerererrext e ppphelale aveven : f . . wawecicurr\n",
      "Epoch [47/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:02,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -10.1719, std: 7.6367, min: -29.9062, max: 14.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:48<00:00, 29.59it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Train Loss: 2.2205, Validation Loss: 2.2382\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 47!\n",
      "Sample Generated Text:\n",
      "The ... fotulolearenanionanan Arerorertarorory . ve a a a  ny uno . .. .......... . a . . ... ! cod ted tiditigitigoginon al . . . .\n",
      "Epoch [48/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<31:03,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -10.4219, std: 7.7500, min: -30.2969, max: 14.1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:48<00:00, 29.62it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 90.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Train Loss: 2.2165, Validation Loss: 2.2364\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 48!\n",
      "Sample Generated Text:\n",
      "The e e t it itistis isisitee t e t t , , , , , , , , , , , , , , , , , , , , , , , , , , , t , , , , , , Gan annanntanitenonenseres\n",
      "Epoch [49/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:07,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -10.4844, std: 7.8438, min: -29.8750, max: 15.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:48<00:00, 29.59it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 90.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Train Loss: 2.2129, Validation Loss: 2.2335\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 49!\n",
      "Sample Generated Text:\n",
      "The Jaracivalisooof ffe fffoffffforyoeriss seessstand andalatentrenerenerurintratrt mammmm 2 2 2 2 2 2 2 2 2 2 in ion ion ion onecon\n",
      "Epoch [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<29:52,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -10.7422, std: 7.9336, min: -31.3281, max: 16.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:48<00:00, 29.61it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 90.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Train Loss: 2.2096, Validation Loss: 2.2326\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 50!\n",
      "Sample Generated Text:\n",
      "The Tagange in it is a asasalal a a a avedededed ar . .. Hotontal Sisi s isindsunun in Mant ontonononttint at t t . 2 is ic a cas s \n",
      "Epoch [51/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:09,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -10.7344, std: 7.9922, min: -31.5312, max: 15.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:54<00:00, 29.33it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 88.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Train Loss: 2.2065, Validation Loss: 2.2327\n",
      "No improvement in validation loss for 1 epochs.\n",
      "Checkpoint saved at epoch 51!\n",
      "Sample Generated Text:\n",
      "The Tenianalalusastanstrtst , , , , , , , , , , , , , , , , , , , , , , , , , 4 , , , , , , , , , , , , , , , , , , , , , , , , , Ar\n",
      "Epoch [52/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:38,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -10.8984, std: 8.0547, min: -32.3750, max: 14.8516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:48<00:00, 29.60it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Train Loss: 2.2036, Validation Loss: 2.2310\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 52!\n",
      "Sample Generated Text:\n",
      "The thend 1 ime Gun an aay Tays anend 1 is Assenininianinintent , , , , , , , , , , , , , , , , , La Le Lit Lilsiol rrllillellllllll\n",
      "Epoch [53/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:34,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.1406, std: 8.1484, min: -31.3281, max: 15.5234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:48<00:00, 29.60it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 90.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Train Loss: 2.2008, Validation Loss: 2.2304\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 53!\n",
      "Sample Generated Text:\n",
      "The Theranconcon an anon Feantiton a isossthesh as t ttt o hoon one on ion iomalal d 7 7 vedieiortin int 3th al alllllillilllllallll\n",
      "Epoch [54/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<31:22,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.2734, std: 8.2734, min: -33.8125, max: 15.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:49<00:00, 29.58it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 90.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Train Loss: 2.1981, Validation Loss: 2.2302\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 54!\n",
      "Sample Generated Text:\n",
      "The Tas s aseappoppland and appppppppppppplas sesererbeverererss ffipepentte oteseogatenturrry r a . fendfrdrefe Sos Scrd ct ctiel i\n",
      "Epoch [55/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<31:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.3125, std: 8.3516, min: -32.4375, max: 15.5156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:49<00:00, 29.56it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Train Loss: 2.1955, Validation Loss: 2.2297\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 55!\n",
      "Sample Generated Text:\n",
      "The Tund and an a a isissuss  s  ss as on to t o to ove , , , , , , , , , , , hoone anamime . . at avivovinvintstat a l gengagagagag\n",
      "Epoch [56/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<31:17,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.3438, std: 8.3359, min: -33.8125, max: 17.1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [12:23<00:00, 23.43it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:43<00:00, 42.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Train Loss: 2.1929, Validation Loss: 2.2301\n",
      "No improvement in validation loss for 1 epochs.\n",
      "Checkpoint saved at epoch 56!\n",
      "Sample Generated Text:\n",
      "The TBTis TuTuTuTTecatict ito t t t it , , , , , , , , , , , , , , , , , , , , , , , hoochonstt atr atrrarith the ....... we awawami\n",
      "Epoch [57/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<42:49,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.5156, std: 8.4375, min: -35.1875, max: 16.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [11:17<00:00, 25.72it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 88.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Train Loss: 2.1904, Validation Loss: 2.2292\n",
      "Best model saved!\n",
      "Checkpoint saved at epoch 57!\n",
      "Sample Generated Text:\n",
      "The Thershosholullllillinginin int at  atsisthishieshisuniananenenananann 2 2 22 2 wan a a a a ad s a heathers ssiloll tlllllllollll\n",
      "Epoch [58/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<31:06,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.5703, std: 8.4922, min: -32.6562, max: 19.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [10:12<00:00, 28.46it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Train Loss: 2.1881, Validation Loss: 2.2299\n",
      "No improvement in validation loss for 1 epochs.\n",
      "Checkpoint saved at epoch 58!\n",
      "Sample Generated Text:\n",
      "The Thennncosoblory any \" \" \" \" \" \" \" \" \" \" sitat ' ' ' ' ' ' a a at at \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" Wel Wilill\n",
      "Epoch [59/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<30:28,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.5234, std: 8.4688, min: -32.9688, max: 17.4219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [09:49<00:00, 29.55it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Train Loss: 2.1858, Validation Loss: 2.2299\n",
      "No improvement in validation loss for 2 epochs.\n",
      "Checkpoint saved at epoch 59!\n",
      "Sample Generated Text:\n",
      "The TT Ta Tas sasisissssys : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : , : Lilerrerer rnd and and and \n",
      "Epoch [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<32:55,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.7656, std: 8.6016, min: -33.6875, max: 16.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████| 17428/17428 [10:13<00:00, 28.42it/s]\n",
      "Validation: 100%|███████████████████████████| 1843/1843 [00:20<00:00, 89.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Train Loss: 2.1835, Validation Loss: 2.2300\n",
      "No improvement in validation loss for 3 epochs.\n",
      "Checkpoint saved at epoch 60!\n",
      "Sample Generated Text:\n",
      "The The Thelin ien iondiong angannd III IIIII II I I I I w I I II II I I I I I Ithata al all annnnennntrntrrerroroly onthen . ft ati\n",
      "Epoch [61/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                               | 1/17428 [00:00<31:02,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits stats: mean: -11.6875, std: 8.5469, min: -34.7188, max: 18.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|██████████████████▌        | 11981/17428 [07:08<03:13, 28.09it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------\n",
    "# 1. Load and Prepare Data\n",
    "# -----------------------\n",
    "wiki = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "# Use a small subset for quicker training; adjust these as needed.\n",
    "train_size = int(len(wiki[\"train\"]) * 0.1)\n",
    "val_size = int(len(wiki[\"validation\"]) * 0.1)\n",
    "\n",
    "# Shuffle and select only the subset\n",
    "train_subset = wiki[\"train\"].shuffle(seed=42).select(range(train_size))\n",
    "val_subset = wiki[\"validation\"].shuffle(seed=42).select(range(val_size))\n",
    "\n",
    "# Use the subset texts instead of the full dataset\n",
    "train_text = \"\\n\".join(train_subset[\"text\"])\n",
    "val_text = \"\\n\".join(val_subset[\"text\"])\n",
    "\n",
    "# Convert text to a tensor of raw byte values using UTF-8 encoding\n",
    "train_bytes = torch.tensor(list(train_text.encode('utf-8')), dtype=torch.long)\n",
    "val_bytes = torch.tensor(list(val_text.encode('utf-8')), dtype=torch.long)\n",
    "\n",
    "# -----------------------\n",
    "# 2. Create a Dataset Class with Deterministic Hashing\n",
    "# -----------------------\n",
    "class WikiTextDataset(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "\n",
    "    def deterministic_hash(self, input_seq):\n",
    "        # A simple deterministic hash: multiply by 31, add 17, modulo 256.\n",
    "        return (input_seq * 31 + 17) % 256\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq = self.data[idx:idx + self.seq_len]\n",
    "        target_seq = self.data[idx + 1:idx + self.seq_len + 1]\n",
    "        # Compute hash deterministically from the input sequence\n",
    "        hash_seq = self.deterministic_hash(input_seq)\n",
    "        return input_seq, hash_seq, target_seq\n",
    "\n",
    "seq_len = 128\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = WikiTextDataset(train_bytes, seq_len)\n",
    "val_dataset = WikiTextDataset(val_bytes, seq_len)\n",
    "\n",
    "# Increase number of workers and enable pin_memory for faster data loading (if using GPU)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "byte_dim = 128\n",
    "patch_dim = 256\n",
    "vocab_size = 256  # Bytes: 0-255\n",
    "n_heads = 8\n",
    "ff_dim = 1024\n",
    "n_encoder = 4\n",
    "n_decoder = 4\n",
    "n_global = 6\n",
    "dropout = 0.1\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ByteLatentTransformer(\n",
    "    byte_dim=byte_dim,\n",
    "    patch_dim=patch_dim,\n",
    "    vocab_size=vocab_size,\n",
    "    n_heads=n_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    n_encoder=n_encoder,\n",
    "    n_decoder=n_decoder,\n",
    "    n_global=n_global,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# -----------------------\n",
    "# 4. Checkpoint Utilities\n",
    "# -----------------------\n",
    "def save_checkpoint(epoch, model, optimizer, train_loss, val_loss, best_val_loss, filepath=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved at epoch {epoch}!\")\n",
    "\n",
    "def load_checkpoint(filepath=\"checkpoint.pth\"):\n",
    "    if os.path.exists(filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        print(f\"Checkpoint loaded from epoch {checkpoint['epoch']}!\")\n",
    "        return checkpoint\n",
    "    else:\n",
    "        print(\"No checkpoint found!\")\n",
    "        return None\n",
    "\n",
    "# -----------------------\n",
    "# 5. Helper Functions: Plot Loss and Generate Text with Temperature Sampling\n",
    "# -----------------------\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(range(1, len(train_losses)+1), train_losses, label='Train Loss', marker='o')\n",
    "    plt.plot(range(1, len(val_losses)+1), val_losses, label='Val Loss', marker='o')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "def generate_text_for_sample(model, input_seq, device, length, temperature=1.0):\n",
    "    model.eval()\n",
    "    # Compute deterministic hash for the input sequence\n",
    "    hash_seq = (input_seq * 31 + 17) % 256\n",
    "    generated_text = \"\".join([chr(x.item()) for x in input_seq[0]])\n",
    "    for _ in range(length):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, hash_seq, None)\n",
    "            logits = output[0, -1] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_byte = torch.multinomial(probs, num_samples=1).item()\n",
    "            generated_text += chr(next_byte)\n",
    "            input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[next_byte]], device=device)], dim=1)\n",
    "            hash_seq = (input_seq * 31 + 17) % 256\n",
    "    return generated_text\n",
    "\n",
    "# -----------------------\n",
    "# 6. Training Loop with Mixed Precision, Early Stopping, Checkpointing, and Logging\n",
    "# -----------------------\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "early_stop_patience = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "def train_model():\n",
    "    global train_losses, val_losses, epochs_no_improve\n",
    "    best_val_loss = float('inf')\n",
    "    start_epoch = 0\n",
    "    checkpoint = load_checkpoint()\n",
    "    if checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        train_losses = checkpoint['train_loss']\n",
    "        val_losses = checkpoint['val_loss']\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "        start_epoch = checkpoint['epoch']\n",
    "    \n",
    "    scaler = torch.amp.GradScaler()\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        tot_loss = 0\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        for i, (byte_seq, hash_seq, target_seq) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "            byte_seq = byte_seq.to(device, non_blocking=True)\n",
    "            hash_seq = hash_seq.to(device, non_blocking=True)\n",
    "            target_seq = target_seq.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(byte_seq, hash_seq, None)\n",
    "                if i == 0:\n",
    "                    print(\"Logits stats: mean: {:.4f}, std: {:.4f}, min: {:.4f}, max: {:.4f}\".format(\n",
    "                        outputs.mean().item(), outputs.std().item(), outputs.min().item(), outputs.max().item()))\n",
    "                outputs = outputs.view(-1, vocab_size)\n",
    "                target_seq = target_seq.view(-1)\n",
    "                loss = criterion(outputs, target_seq)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            tot_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = tot_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        tot_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for byte_seq, hash_seq, target_seq in tqdm(val_loader, desc=\"Validation\"):\n",
    "                byte_seq = byte_seq.to(device, non_blocking=True)\n",
    "                hash_seq = hash_seq.to(device, non_blocking=True)\n",
    "                target_seq = target_seq.to(device, non_blocking=True)\n",
    "                with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                    outputs = model(byte_seq, hash_seq, None)\n",
    "                    outputs = outputs.view(-1, vocab_size)\n",
    "                    target_seq = target_seq.view(-1)\n",
    "                    l = criterion(outputs, target_seq)\n",
    "                tot_val_loss += l.item()\n",
    "        avg_val_loss = tot_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), \"BLT_wikitext.pth\")\n",
    "            print(\"Best model saved!\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
    "            if epochs_no_improve >= early_stop_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        save_checkpoint(epoch+1, model, optimizer, train_losses, val_losses, best_val_loss)\n",
    "        print(\"Sample Generated Text:\")\n",
    "        sample_prompt = \"The \"  # A common prompt in Wiki text\n",
    "        sample_input = torch.tensor([ord(c) for c in sample_prompt], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        print(generate_text_for_sample(model, sample_input, device, length=seq_len, temperature=0.8))\n",
    "    \n",
    "    plot_loss(train_losses, val_losses)\n",
    "\n",
    "# Start training\n",
    "train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7d32e-5195-42ee-9c33-982e94f3ee64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
