{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b768b8-54d6-46c2-9294-fc350d656c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fa0359-1b15-4db3-ba89-b3b33bf7a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cuda():\n",
    "    return DEVICE.backend == \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0e0744-861d-4628-8e83-6bd9879a3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def matmul_kernel(a_ptr,b_ptr,c_ptr,\n",
    "                  M,N,K,\n",
    "                  stride_am,stride_ak,\n",
    "                  stride_bk,stride_bn,\n",
    "                  stride_cm,stride_cn,\n",
    "                  BLOCK_SIZE_M:tl.constexpr,BLOCK_SIZE_N:tl.constexpr,BLOCK_SIZE_K:tl.constexpr,\n",
    "                  GROUP_SIZE_M:tl.constexpr,\n",
    "                  ACTIVATION:tl.constexpr):\n",
    "    pid = tl.program_id(0)\n",
    "    grid_n = tl.cdiv(N,BLOCK_SIZE_N)\n",
    "    pid_m = pid // grid_n \n",
    "    pid_n = pid % grid_n\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0,BLOCK_SIZE_M)) \n",
    "    mask_am = offs_am < M\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0,BLOCK_SIZE_N))\n",
    "    mask_bn = offs_bn < N\n",
    "    offs_k = tl.arange(0,BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:,None] * stride_am + offs_k[None,:] * stride_ak)\n",
    "    b_ptrs = b_ptr + (offs_k[:,None] * stride_bk + offs_bn[None,:] * stride_bn)\n",
    "    acc = tl.zeros((BLOCK_SIZE_M,BLOCK_SIZE_N),dtype=tl.float32)\n",
    "\n",
    "    for k in range(0,tl.cdiv(K,BLOCK_SIZE_K)):\n",
    "        a = tl.load(a_ptrs,mask=mask_am[None,:] < K - k * BLOCK_SIZE_K,other=0.0)\n",
    "        b = tl.load(b_ptrs,mask=mask_bn[:,None] < K - k * BLOCK_SIZE_K,other=0.0)\n",
    "        acc = tl.dot(a,b,acc)\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "    if ACTIVATION == 'leaky_relu':\n",
    "        acc = leaky_relu(acc)\n",
    "    c = acc.to(tl.float16)\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0,BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0,BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + (offs_cm[:,None] * stride_cm + offs_cn[None,:] * stride_cn)\n",
    "    mask_c = (offs_cm[:,None] < M) & (offs_cn[None,:] < N)\n",
    "    tl.store(c_ptrs,c,mask=mask_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a1f647-0766-43f0-ac72-d9fd1c287a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def leaky_relu(x):\n",
    "    return tl.where(x>=0,x,0.01 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef71a22d-04ee-4be9-be5c-76fb2c72696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b,activation=\"\"):\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dim\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    M, K = a.shape\n",
    "    K, N = b.shape\n",
    "    BLOCK_SIZE_M = 32\n",
    "    BLOCK_SIZE_N = 32\n",
    "    BLOCK_SIZE_K = 32\n",
    "    GROUP_SIZE_M = 8\n",
    "    c = torch.empty((M,N),device=a.device,dtype=torch.float16)\n",
    "    grid = lambda META: (triton.cdiv(M,META['BLOCK_SIZE_M']) * triton.cdiv(N,META['BLOCK_SIZE_N']),)\n",
    "    matmul_kernel[grid](a,b,c,\n",
    "                        M,N,K,\n",
    "                        a.stride(0),a.stride(1),\n",
    "                        b.stride(0),b.stride(1),\n",
    "                        c.stride(0),c.stride(1),\n",
    "                        BLOCK_SIZE_M,BLOCK_SIZE_N,BLOCK_SIZE_K,\n",
    "                        GROUP_SIZE_M,\n",
    "                        ACTIVATION=activation)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dec026fc-8611-4c23-8163-c7a93217cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triton_output_with_fp16_inputs=tensor([[ 48.4688,  28.1406, -28.7656,  ..., -23.0000,  15.6641,  13.9219],\n",
      "        [ 33.5625,  -2.6055,  14.5000,  ...,  -0.0503,  18.5625,  -9.4453],\n",
      "        [ -4.6367,  -7.6758,  30.5625,  ...,  20.5469,  35.0312,  -5.9375],\n",
      "        ...,\n",
      "        [-29.6562,  -0.5352,  29.2344,  ...,  45.6875, -20.1719, -15.7109],\n",
      "        [ 23.1094,  -6.1484, -17.9062,  ...,  14.5547,  21.3125, -19.8750],\n",
      "        [  5.2539,  31.2344, -14.6641,  ..., -16.0938,  24.2812,   7.0430]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "torch_output_with_fp16_inputs=tensor([[ 48.4688,  28.1406, -28.7656,  ..., -23.0000,  15.6641,  13.9219],\n",
      "        [ 33.5625,  -2.6055,  14.5000,  ...,  -0.0503,  18.5625,  -9.4453],\n",
      "        [ -4.6367,  -7.6758,  30.5625,  ...,  20.5469,  35.0312,  -5.9375],\n",
      "        ...,\n",
      "        [-29.6562,  -0.5352,  29.2344,  ...,  45.6875, -20.1719, -15.7109],\n",
      "        [ 23.1094,  -6.1484, -17.9062,  ...,  14.5547,  21.3125, -19.8750],\n",
      "        [  5.2539,  31.2344, -14.6641,  ..., -16.0938,  24.2812,   7.0430]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "✅ Triton and Torch match\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "a = torch.randn((512, 512), device=DEVICE, dtype=torch.float16)\n",
    "b = torch.randn((512, 512), device=DEVICE, dtype=torch.float16)\n",
    "triton_output = matmul(a, b)\n",
    "torch_output = torch.matmul(a, b)\n",
    "print(f\"triton_output_with_fp16_inputs={triton_output}\")\n",
    "print(f\"torch_output_with_fp16_inputs={torch_output}\")\n",
    "\n",
    "if torch.allclose(triton_output, torch_output, atol=1e-2):\n",
    "    print(\"✅ Triton and Torch match\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b508752-95e1-43ee-a170-6d7f7fab8767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
